{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f307e49a-3f2e-47f4-a529-7a249a8753d8",
   "metadata": {},
   "source": [
    "##### Training Objective:\n",
    "\n",
    "The goal of this loop is to train the small network to re-embed RoBERTa’s output embeddings in such a way that concept-related information is minimized.\n",
    "This is achieved by making the concept classifier's predictions approach a uniform distribution using KL divergence as the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ca2741-2e0d-4275-873c-5f46737e0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "from transformers import AutoTokenizer, AutoModel, RobertaModel\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import nbimporter\n",
    "from concept_classification import ConceptClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c4e34c8-5933-4612-a55d-df727b0de2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805d837b-c4b4-4a7b-abc1-c3417b3d2b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load RoBERTa Model and Tokenizer\n",
    "roberta_model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87200fd8-d458-45f8-9ff8-f9e21bbe2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, bottleneck_dim):\n",
    "        \"\"\"\n",
    "        Small network to re-embed RoBERTa output.\n",
    "        \n",
    "        Args:\n",
    "        - input_dim (int): Dimensionality of RoBERTa's output embeddings.\n",
    "        - bottleneck_dim (int): Dimensionality of the bottleneck layer.\n",
    "        \"\"\"\n",
    "        super(SmallNetwork, self).__init__()\n",
    "        self.project = nn.Linear(input_dim, bottleneck_dim)\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(d_model=bottleneck_dim, nhead=4, batch_first=True)\n",
    "        self.expand = nn.Linear(bottleneck_dim + input_dim, input_dim)  # Adjust for concatenation\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the small network.\n",
    "        \n",
    "        Args:\n",
    "        - x (torch.Tensor): Input embeddings from RoBERTa (batch_size x input_dim).\n",
    "        \n",
    "        Returns:\n",
    "        - torch.Tensor: Re-embedded representation (batch_size x input_dim).\n",
    "        \"\"\"\n",
    "        identity = x  # Save original input for residual connection\n",
    "\n",
    "        # Project and transform input\n",
    "        x = self.project(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer_layer(x)\n",
    "\n",
    "        # Concatenate residual and transformed outputs\n",
    "        x = torch.cat([x, identity], dim=-1)  # Concatenate along feature dimension\n",
    "        x = self.expand(x)  # Reduce to original dimensionality\n",
    "        x = self.layer_norm(x)  # Normalize the output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb388f1f-086a-450d-abab-00e6ed0471ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, bottleneck_dim):\n",
    "        \"\"\"\n",
    "        Inverse network to reconstruct original embeddings from re-embedded outputs.\n",
    "        \n",
    "        Args:\n",
    "        - input_dim (int): Dimensionality of original embeddings.\n",
    "        - bottleneck_dim (int): Dimensionality of bottleneck embeddings.\n",
    "        \"\"\"\n",
    "        super(InverseNetwork, self).__init__()\n",
    "        self.project = nn.Linear(input_dim, bottleneck_dim)\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(d_model=bottleneck_dim, nhead=4, batch_first=True)\n",
    "        self.expand = nn.Linear(bottleneck_dim + input_dim, input_dim)  # Adjust for concatenation\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the inverse network.\n",
    "        \n",
    "        Args:\n",
    "        - x (torch.Tensor): Re-embedded embeddings (batch_size x seq_length x input_dim).\n",
    "        \n",
    "        Returns:\n",
    "        - torch.Tensor: Reconstructed original embeddings (batch_size x seq_length x input_dim).\n",
    "        \"\"\"\n",
    "        identity = x  # Save original input for residual connection\n",
    "\n",
    "        # Project and transform input\n",
    "        x = self.project(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer_layer(x)\n",
    "\n",
    "        # Concatenate residual and transformed outputs\n",
    "        x = torch.cat([x, identity], dim=-1)  # Concatenate along feature dimension\n",
    "        x = self.expand(x)  # Reduce to original dimensionality\n",
    "        x = self.layer_norm(x)  # Normalize the output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89403fe8-4b54-490e-93fc-975576eb1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_uniform_loss(logits, num_classes, epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Compute KL divergence between predicted logits and a uniform distribution.\n",
    "    \n",
    "    Args:\n",
    "    - logits (torch.Tensor): Output logits from the concept classifier (batch_size x num_classes).\n",
    "    - num_classes (int): Number of concept classes.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: KL divergence loss.\n",
    "    \"\"\"\n",
    "    # Convert logits to probabilities using softmax\n",
    "    probs = F.softmax(logits, dim=-1) + epsilon  # Add epsilon to avoid log(0)\n",
    "    \n",
    "    # Define uniform target distribution\n",
    "    uniform_dist = torch.full_like(probs, 1.0 / num_classes)\n",
    "    \n",
    "    # Compute KL divergence\n",
    "    kl_loss = F.kl_div(probs.log(), uniform_dist, reduction='batchmean')  # Log probabilities are required\n",
    "    return kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffdee827-31fb-40ff-8390-a058a251dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(kl_loss, original, reconstructed, lambda_reconstruction=0.1):\n",
    "    \"\"\"\n",
    "    Combine KL divergence loss with reconstruction loss.\n",
    "    \n",
    "    Args:\n",
    "    - kl_loss (torch.Tensor): KL divergence loss.\n",
    "    - original (torch.Tensor): Original embeddings.\n",
    "    - reconstructed (torch.Tensor): Reconstructed embeddings.\n",
    "    - lambda_reconstruction (float): Weight for reconstruction loss.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: Combined loss.\n",
    "    \"\"\"\n",
    "    reconstruction_loss = F.mse_loss(reconstructed, original)\n",
    "    return kl_loss + lambda_reconstruction * reconstruction_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6281c6-6e0b-438f-b70d-9f26bda488b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV\n",
    "data_path = \"imbalanced_concepts.csv\"  # Replace with your CSV path\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1691590a-7441-460b-9657-802b68a404a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and process data\n",
    "def tokenize_data(reviews):\n",
    "    tokenized_data = tokenizer(reviews, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = tokenized_data[\"input_ids\"]\n",
    "    attention_mask = tokenized_data[\"attention_mask\"]\n",
    "    return TensorDataset(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e897c411-e7ae-418e-bee1-b0a7f6867c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "dataset = tokenize_data(data['clean_text'].tolist())\n",
    "data_size = len(dataset)\n",
    "train_size = int(0.8 * data_size)\n",
    "val_size = data_size - train_size\n",
    "\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ffd1184-84c3-4729-84fc-1cceb7e11de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_2936066/1009610697.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  concept_classifier.load_state_dict(torch.load(\"concept_classifier.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConceptClassifier(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (attention): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (swiglu): SwiGLU(\n",
       "    (linear1): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (linear2): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (gelu): GELU(approximate='none')\n",
       "  )\n",
       "  (fc2): Linear(in_features=384, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained Concept Classifier\n",
    "concept_classifier = ConceptClassifier(num_labels=2).to(device)\n",
    "concept_classifier.load_state_dict(torch.load(\"concept_classifier.pt\"))\n",
    "concept_classifier.eval()  # Freeze concept classifier during small network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4de7d2af-c2b0-4cc7-9459-99a613605eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize networks\n",
    "small_network = SmallNetwork(input_dim=768, bottleneck_dim=384).to(device)\n",
    "inverse_network = InverseNetwork(input_dim=768, bottleneck_dim=384).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a40c7dc-b5dd-4af2-aa07-ec9d81dcc3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InverseNetwork(\n",
       "  (project): Linear(in_features=768, out_features=384, bias=True)\n",
       "  (transformer_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=384, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=384, bias=True)\n",
       "    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (expand): Linear(in_features=1152, out_features=768, bias=True)\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (activation): GELU(approximate='none')\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "# Apply initialization\n",
    "small_network.apply(init_weights)\n",
    "inverse_network.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6932debe-0170-46d8-a7fd-51f90374c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "small_network_optimizer = optim.AdamW(small_network.parameters(), lr=0.0003)\n",
    "inverse_network_optimizer = optim.AdamW(inverse_network.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef73fb-bc81-41f9-8466-9f5942e574d2",
   "metadata": {},
   "source": [
    "##### Validation and Evaluation \n",
    "Concept labels can be used indirectly to measure how well the small network has removed concept information. The key metric will be the concept classifier’s accuracy on the re-embedded outputs. If the accuracy is low, it indicates that the small network has successfully removed concept information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e745d7c-3f25-4897-95e8-5fb73fe2943c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Training: 100%|█████████████████████████████████████████████████| 211/211 [01:37<00:00,  2.16it/s]\n",
      "Epoch 1/100 - Validation: 100%|█████████████████████████████████████████████████| 53/53 [00:20<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]\n",
      "  Train Loss: 9.7019\n",
      "  Val Loss:   9.6939\n",
      "  Validation loss improved from inf to 9.6939. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 - Training: 100%|█████████████████████████████████████████████████| 211/211 [01:36<00:00,  2.19it/s]\n",
      "Epoch 2/100 - Validation: 100%|█████████████████████████████████████████████████| 53/53 [00:20<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100]\n",
      "  Train Loss: 9.6913\n",
      "  Val Loss:   9.6868\n",
      "  Validation loss improved from 9.6939 to 9.6868. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 - Training: 100%|█████████████████████████████████████████████████| 211/211 [01:36<00:00,  2.19it/s]\n",
      "Epoch 3/100 - Validation: 100%|█████████████████████████████████████████████████| 53/53 [00:20<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100]\n",
      "  Train Loss: 9.6849\n",
      "  Val Loss:   9.6815\n",
      "  Validation loss improved from 9.6868 to 9.6815. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 - Training: 100%|█████████████████████████████████████████████████| 211/211 [01:33<00:00,  2.25it/s]\n",
      "Epoch 4/100 - Validation: 100%|█████████████████████████████████████████████████| 53/53 [00:20<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100]\n",
      "  Train Loss: 9.6800\n",
      "  Val Loss:   9.6774\n",
      "  Validation loss improved from 9.6815 to 9.6774. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 - Training: 100%|█████████████████████████████████████████████████| 211/211 [01:36<00:00,  2.19it/s]\n",
      "Epoch 5/100 - Validation: 100%|█████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100]\n",
      "  Train Loss: 9.6762\n",
      "  Val Loss:   9.6742\n",
      "  Validation loss improved from 9.6774 to 9.6742. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 - Training: 100%|█████████████████████████████████████████████████| 211/211 [01:35<00:00,  2.21it/s]\n",
      "Epoch 6/100 - Validation: 100%|█████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100]\n",
      "  Train Loss: 9.6734\n",
      "  Val Loss:   9.6718\n",
      "  Validation loss improved from 9.6742 to 9.6718. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 - Training: 100%|█████████████████████████████████████████████████| 211/211 [01:38<00:00,  2.14it/s]\n",
      "Epoch 7/100 - Validation: 100%|█████████████████████████████████████████████████| 53/53 [00:20<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100]\n",
      "  Train Loss: 9.6713\n",
      "  Val Loss:   9.6703\n",
      "  Validation loss improved from 9.6718 to 9.6703. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 - Training: 100%|█████████████████████████████████████████████████| 211/211 [01:35<00:00,  2.21it/s]\n",
      "Epoch 8/100 - Validation: 100%|█████████████████████████████████████████████████| 53/53 [00:20<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100]\n",
      "  Train Loss: 9.6702\n",
      "  Val Loss:   9.6697\n",
      "  Validation loss improved from 9.6703 to 9.6697. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 - Training: 100%|█████████████████████████████████████████████████| 211/211 [01:38<00:00,  2.15it/s]\n",
      "Epoch 9/100 - Validation: 100%|█████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100]\n",
      "  Train Loss: 9.6698\n",
      "  Val Loss:   9.6695\n",
      "  Validation loss improved from 9.6697 to 9.6695. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:38<00:00,  2.15it/s]\n",
      "Epoch 10/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100]\n",
      "  Train Loss: 9.6697\n",
      "  Val Loss:   9.6695\n",
      "  Validation loss improved from 9.6695 to 9.6695. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:34<00:00,  2.23it/s]\n",
      "Epoch 11/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100]\n",
      "  Train Loss: 9.6696\n",
      "  Val Loss:   9.6694\n",
      "  Validation loss improved from 9.6695 to 9.6694. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:34<00:00,  2.23it/s]\n",
      "Epoch 12/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:21<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100]\n",
      "  Train Loss: 9.6695\n",
      "  Val Loss:   9.6694\n",
      "  Validation loss improved from 9.6694 to 9.6694. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:39<00:00,  2.11it/s]\n",
      "Epoch 13/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100]\n",
      "  Train Loss: 9.6695\n",
      "  Val Loss:   9.6693\n",
      "  Validation loss improved from 9.6694 to 9.6693. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:37<00:00,  2.16it/s]\n",
      "Epoch 14/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100]\n",
      "  Train Loss: 9.6694\n",
      "  Val Loss:   9.6693\n",
      "  Validation loss improved from 9.6693 to 9.6693. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:36<00:00,  2.18it/s]\n",
      "Epoch 15/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:21<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100]\n",
      "  Train Loss: 9.6694\n",
      "  Val Loss:   9.6693\n",
      "  Validation loss improved from 9.6693 to 9.6693. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:39<00:00,  2.13it/s]\n",
      "Epoch 16/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:20<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100]\n",
      "  Train Loss: 9.6693\n",
      "  Val Loss:   9.6692\n",
      "  Validation loss improved from 9.6693 to 9.6692. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:35<00:00,  2.21it/s]\n",
      "Epoch 17/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:20<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100]\n",
      "  Train Loss: 9.6693\n",
      "  Val Loss:   9.6692\n",
      "  Validation loss improved from 9.6692 to 9.6692. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:36<00:00,  2.18it/s]\n",
      "Epoch 18/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:18<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100]\n",
      "  Train Loss: 9.6693\n",
      "  Val Loss:   9.6692\n",
      "  Validation loss improved from 9.6692 to 9.6692. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:34<00:00,  2.23it/s]\n",
      "Epoch 19/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100]\n",
      "  Train Loss: 9.6692\n",
      "  Val Loss:   9.6692\n",
      "  Validation loss improved from 9.6692 to 9.6692. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:34<00:00,  2.23it/s]\n",
      "Epoch 20/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100]\n",
      "  Train Loss: 9.6692\n",
      "  Val Loss:   9.6692\n",
      "  Validation loss improved from 9.6692 to 9.6692. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:57<00:00,  1.79it/s]\n",
      "Epoch 21/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100]\n",
      "  Train Loss: 9.6692\n",
      "  Val Loss:   9.6691\n",
      "  Validation loss improved from 9.6692 to 9.6691. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.76it/s]\n",
      "Epoch 22/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100]\n",
      "  Train Loss: 9.6692\n",
      "  Val Loss:   9.6691\n",
      "  Validation loss improved from 9.6691 to 9.6691. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 23/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100]\n",
      "  Train Loss: 9.6691\n",
      "  Val Loss:   9.6691\n",
      "  Validation loss improved from 9.6691 to 9.6691. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 24/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100]\n",
      "  Train Loss: 9.6691\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6691 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.77it/s]\n",
      "Epoch 25/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100]\n",
      "  Train Loss: 9.6691\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6690 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.73it/s]\n",
      "Epoch 26/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100]\n",
      "  Train Loss: 9.6691\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6690 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.76it/s]\n",
      "Epoch 27/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6690 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.73it/s]\n",
      "Epoch 28/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6690 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.76it/s]\n",
      "Epoch 29/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6690 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.77it/s]\n",
      "Epoch 30/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6690 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 31/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6690 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 32/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6690 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.77it/s]\n",
      "Epoch 33/100 - Validation: 100%|█████████████████████████████████████████████| 53/53 [00:24<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6690\n",
      "  Validation loss improved from 9.6690 to 9.6690. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:58<00:00,  1.78it/s]\n",
      "Epoch 34/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6690 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:57<00:00,  1.79it/s]\n",
      "Epoch 35/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.77it/s]\n",
      "Epoch 36/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100]\n",
      "  Train Loss: 9.6690\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 37/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:23<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:58<00:00,  1.78it/s]\n",
      "Epoch 38/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:58<00:00,  1.78it/s]\n",
      "Epoch 39/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.77it/s]\n",
      "Epoch 40/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 41/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:58<00:00,  1.78it/s]\n",
      "Epoch 42/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:58<00:00,  1.78it/s]\n",
      "Epoch 43/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.76it/s]\n",
      "Epoch 44/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:58<00:00,  1.78it/s]\n",
      "Epoch 45/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:58<00:00,  1.78it/s]\n",
      "Epoch 46/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 47/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 48/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 49/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.76it/s]\n",
      "Epoch 50/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.73it/s]\n",
      "Epoch 51/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.74it/s]\n",
      "Epoch 52/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 2/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 53/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.73it/s]\n",
      "Epoch 54/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:58<00:00,  1.77it/s]\n",
      "Epoch 55/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 56/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.74it/s]\n",
      "Epoch 57/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 2/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.77it/s]\n",
      "Epoch 58/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.76it/s]\n",
      "Epoch 59/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  Validation loss improved from 9.6689 to 9.6689. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:59<00:00,  1.76it/s]\n",
      "Epoch 60/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.74it/s]\n",
      "Epoch 61/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:23<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6688\n",
      "  Validation loss improved from 9.6689 to 9.6688. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:02<00:00,  1.73it/s]\n",
      "Epoch 62/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 63/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6688\n",
      "  Validation loss improved from 9.6688 to 9.6688. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:03<00:00,  1.71it/s]\n",
      "Epoch 64/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6689\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.73it/s]\n",
      "Epoch 65/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6688\n",
      "  No improvement in validation loss for 2/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.73it/s]\n",
      "Epoch 66/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6688\n",
      "  Validation loss improved from 9.6688 to 9.6688. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.73it/s]\n",
      "Epoch 67/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100]\n",
      "  Train Loss: 9.6689\n",
      "  Val Loss:   9.6688\n",
      "  Validation loss improved from 9.6688 to 9.6688. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [01:58<00:00,  1.78it/s]\n",
      "Epoch 68/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100]\n",
      "  Train Loss: 9.6688\n",
      "  Val Loss:   9.6688\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:00<00:00,  1.75it/s]\n",
      "Epoch 69/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100]\n",
      "  Train Loss: 9.6688\n",
      "  Val Loss:   9.6688\n",
      "  Validation loss improved from 9.6688 to 9.6688. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.74it/s]\n",
      "Epoch 70/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100]\n",
      "  Train Loss: 9.6688\n",
      "  Val Loss:   9.6688\n",
      "  No improvement in validation loss for 1/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.74it/s]\n",
      "Epoch 71/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100]\n",
      "  Train Loss: 9.6688\n",
      "  Val Loss:   9.6688\n",
      "  No improvement in validation loss for 2/3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 - Training: 100%|████████████████████████████████████████████████| 211/211 [02:01<00:00,  1.74it/s]\n",
      "Epoch 72/100 - Validation: 100%|████████████████████████████████████████████████| 53/53 [00:25<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100]\n",
      "  Train Loss: 9.6688\n",
      "  Val Loss:   9.6688\n",
      "  No improvement in validation loss for 3/3 epochs.\n",
      "Early stopping triggered.\n",
      "Best Small Network model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping and Metrics\n",
    "patience = 3\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model_state = None\n",
    "wait = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "roberta_model.eval()\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    small_network.train()\n",
    "    inverse_network.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Training Phase\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Training\"):\n",
    "        input_ids, attention_mask = [x.to(device) for x in batch]\n",
    "\n",
    "        # Forward pass through RoBERTa\n",
    "        with torch.no_grad():\n",
    "            roberta_output = roberta_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            roberta_embeddings = roberta_output.last_hidden_state\n",
    "\n",
    "        # Pass through Small Network\n",
    "        reembedded_output = small_network(roberta_embeddings)\n",
    "\n",
    "        # Train Inverse Network\n",
    "        reconstructed_output = inverse_network(reembedded_output.detach())  # Detach reembedded_output\n",
    "        inverse_network_optimizer.zero_grad()\n",
    "        reconstruction_loss = F.mse_loss(reconstructed_output, roberta_embeddings)  # Original embeddings\n",
    "        reconstruction_loss.backward()\n",
    "        inverse_network_optimizer.step()\n",
    "\n",
    "        # Compute KL divergence loss\n",
    "        logits = concept_classifier(input_ids=None, attention_mask=None, embeddings=reembedded_output, return_probs=False)\n",
    "        kl_loss = kl_uniform_loss(logits, num_classes=2)\n",
    "\n",
    "        # Combine losses for Small Network\n",
    "        total_loss = combined_loss(kl_loss, roberta_embeddings, reconstructed_output.detach())  # Detach reconstructed_output\n",
    "\n",
    "        # Backpropagation for Small Network\n",
    "        small_network_optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(small_network.parameters(), max_norm=1.0)\n",
    "        small_network_optimizer.step()\n",
    "\n",
    "        total_train_loss += total_loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation Phase\n",
    "    small_network.eval()\n",
    "    inverse_network.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Validation\"):\n",
    "            input_ids, attention_mask = [x.to(device) for x in batch]\n",
    "\n",
    "            # Forward pass through RoBERTa\n",
    "            roberta_output = roberta_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            roberta_embeddings = roberta_output.last_hidden_state\n",
    "\n",
    "            # Pass through Small Network\n",
    "            reembedded_output = small_network(roberta_embeddings)\n",
    "\n",
    "            # Reconstruct original embeddings using the Inverse Network\n",
    "            reconstructed_output = inverse_network(reembedded_output)\n",
    "\n",
    "            # Compute KL divergence loss\n",
    "            logits = concept_classifier(input_ids=None, attention_mask=None, embeddings=reembedded_output, return_probs=False)\n",
    "            kl_loss = kl_uniform_loss(logits, num_classes=2)\n",
    "\n",
    "            # Combine losses for Validation\n",
    "            total_loss = combined_loss(kl_loss, roberta_embeddings, reconstructed_output)\n",
    "            total_val_loss += total_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Logging\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early Stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        print(f\"  Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_state = small_network.state_dict()\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        print(f\"  No improvement in validation loss for {wait}/{patience} epochs.\")\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Save the best model\n",
    "if best_model_state:\n",
    "    small_network.load_state_dict(best_model_state)\n",
    "    torch.save(small_network.state_dict(), \"small_network.pt\")\n",
    "    print(\"Best Small Network model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6956509-b5d8-46ca-b207-c34ee7d3cc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "721830da-ceb5-4a14-8ab8-6564dd5ec029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define concept dictionary\n",
    "concept_dict = {'Emotion': ['Emotion', 'Feeling', 'Passion', 'Sentiment', 'Empathy', 'Expression', 'Drama', 'Pathos', 'Intensity', 'Conflict', 'Connection'],\n",
    "                'Story': ['Story', 'Plot', 'Narrative', 'Script', 'Character', 'Arc', 'Theme', 'Conflict', 'Climax', 'Setting', 'Resolution']\n",
    "               }\n",
    "\n",
    "\n",
    "# Tokenize and Process Data with Labels\n",
    "def tokenize_data_with_labels(reviews, labels):\n",
    "    \"\"\"\n",
    "    Tokenize reviews and attach labels for evaluation.\n",
    "    \n",
    "    Args:\n",
    "    - reviews (list of str): Input text data.\n",
    "    - labels (list of int): Concept labels for evaluation.\n",
    "    \n",
    "    Returns:\n",
    "    - TensorDataset: Tokenized input IDs, attention masks, and labels.\n",
    "    \"\"\"\n",
    "    tokenized_data = tokenizer(reviews, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = tokenized_data[\"input_ids\"]\n",
    "    attention_mask = tokenized_data[\"attention_mask\"]\n",
    "    label_ids = torch.tensor(labels, dtype=torch.long)\n",
    "    return TensorDataset(input_ids, attention_mask, label_ids)\n",
    "\n",
    "\n",
    "# Prepare Evaluation Dataset\n",
    "eval_reviews = data['clean_text'].tolist()\n",
    "eval_labels = data['final_concept'].apply(lambda x: list(concept_dict.keys()).index(x)).tolist()\n",
    "eval_dataset = tokenize_data_with_labels(eval_reviews, eval_labels)\n",
    "\n",
    "# Create DataLoader for Evaluation\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5344cc0-fa84-48c1-85dd-1d1fe65edb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Small Network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Small Network: 100%|███████████████████████████████████████████████| 264/264 [02:01<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept Classifier Accuracy on Re-embedded Outputs: 0.2101\n",
      "Average Entropy of Concept Classifier Predictions: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Small Network\n",
    "def evaluate_small_network(small_network, concept_classifier, data_loader, num_classes):\n",
    "    \"\"\"\n",
    "    Evaluate the small network by measuring the concept classifier's accuracy \n",
    "    on the re-embedded outputs.\n",
    "\n",
    "    Args:\n",
    "    - small_network (nn.Module): The trained small network.\n",
    "    - concept_classifier (nn.Module): The concept classifier.\n",
    "    - data_loader (DataLoader): DataLoader for evaluation data.\n",
    "    - num_classes (int): Number of concept classes.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Concept classifier's accuracy on re-embedded outputs.\n",
    "    - entropy (float): Average entropy of concept classifier predictions.\n",
    "    \"\"\"\n",
    "    small_network.eval()\n",
    "    concept_classifier.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_entropy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating Small Network\"):\n",
    "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "            # Forward pass through RoBERTa\n",
    "            roberta_output = roberta_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            roberta_embeddings = roberta_output.last_hidden_state\n",
    "\n",
    "            # Pass through Small Network\n",
    "            reembedded_output = small_network(roberta_embeddings)\n",
    "\n",
    "            # Concept Classifier predictions\n",
    "            probs = concept_classifier(input_ids=None, attention_mask=None, embeddings=reembedded_output, return_probs=True)\n",
    "            predictions = torch.argmax(probs, dim=-1)\n",
    "\n",
    "            # Compute accuracy\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Compute entropy\n",
    "            batch_entropy = -torch.sum(probs * torch.log(probs + 1e-9), dim=1).mean().item()\n",
    "            total_entropy += batch_entropy * labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    avg_entropy = total_entropy / total\n",
    "    return accuracy, avg_entropy\n",
    "\n",
    "\n",
    "# Run Evaluation\n",
    "print(\"\\nEvaluating Small Network...\")\n",
    "test_accuracy, avg_entropy = evaluate_small_network(small_network, concept_classifier, eval_loader, num_classes=2)\n",
    "\n",
    "# Print Evaluation Metrics\n",
    "print(f\"Concept Classifier Accuracy on Re-embedded Outputs: {test_accuracy:.4f}\")\n",
    "print(f\"Average Entropy of Concept Classifier Predictions: {avg_entropy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae82ad0-10d0-422e-bafd-242d304b9e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
